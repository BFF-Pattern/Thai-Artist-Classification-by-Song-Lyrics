{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6631639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp310-cp310-win_amd64.whl (23.9 MB)\n",
      "     ---------------------------------------- 23.9/23.9 MB 1.2 MB/s eta 0:00:00\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.0.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.4/58.4 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\jinnie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.22.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\jinnie\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.8.0)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "     -------------------------------------- 983.8/983.8 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0 smart-open-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts cygdb.exe, cython.exe and cythonize.exe are installed in 'C:\\Users\\jinnie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148481a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230fc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "all_files = glob.glob(\"../data_lyrics/thaisongs/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    song_df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(song_df)\n",
    "\n",
    "song_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1ebba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of round brackets: 6673\n",
      "Number of square brackets: 54\n",
      "Number of curly brackets: 0\n",
      "Number of dot: 16715\n",
      "Number of star: 391\n",
      "Number of semi colon: 46\n",
      "Number of colon: 159\n",
      "Number of exclamation mark: 416\n",
      "Number of slash: 247\n",
      "Number of slashR: 1\n",
      "Number of question mark: 305\n",
      "Number of hashtag: 29\n",
      "Number of percent: 1\n",
      "Number of plus: 22\n",
      "Number of minus: 547\n",
      "Number of comma: 1466\n",
      "Number of single quote: 4960\n",
      "Number of double quote: 18\n",
      "Number of dollar sign: 2\n",
      "Number of ampersand: 44\n",
      "Number of underscore: 226\n"
     ]
    }
   ],
   "source": [
    "# remove !@#$%^&*()_+\n",
    "lyric_in_round_brackets = sum(list(song_df['lyric'].map(lambda s: re.findall(r'\\((.*?)\\)',s))), [])\n",
    "lyric_in_square_brackets = sum(list(song_df['lyric'].map(lambda s: re.findall(r'\\[(.*?)\\]',s))), [])\n",
    "lyric_in_curly_brackets = sum(list(song_df['lyric'].map(lambda s: re.findall(r'\\{(.*?)\\}',s))), [])\n",
    "dot = sum(list(song_df['lyric'].map(lambda s: re.findall('\\.',s))), [])\n",
    "star = sum(list(song_df['lyric'].map(lambda s: re.findall('\\*',s))), [])\n",
    "semi_colon = sum(list(song_df['lyric'].map(lambda s: re.findall('\\;',s))), [])\n",
    "colon = sum(list(song_df['lyric'].map(lambda s: re.findall('\\:',s))), [])\n",
    "exclam_mark = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\!\",s))), [])\n",
    "slash = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\/\",s))), [])\n",
    "slashR = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\\\\",s))), [])\n",
    "question_mark = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\?\",s))), [])\n",
    "hashtag = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\#\",s))), [])\n",
    "percent = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\%\",s))), [])\n",
    "plus = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\+\",s))), [])\n",
    "minus = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\-\",s))), [])\n",
    "comma = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\,\",s))), [])\n",
    "sg_quote = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\'\",s))), [])\n",
    "db_quote = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\\"\",s))), [])\n",
    "dollar_sign = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\$\",s))), [])\n",
    "ampersand = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\&\",s))), [])\n",
    "underscore = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\_\",s))), [])\n",
    "\n",
    "\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\((.*?)\\)', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\[(.*?)\\]', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\{(.*?)\\}', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\.', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\*', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\;', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\:', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\!\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\/\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\\\', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\?\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\#\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\%\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\+\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\-\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\,\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\'\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\\"', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\$', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\&', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\_', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\(|\\)', '', s))\n",
    "\n",
    "\n",
    "\n",
    "print('Number of round brackets: {}'.format(len(lyric_in_round_brackets)))\n",
    "print('Number of square brackets: {}'.format(len(lyric_in_square_brackets)))\n",
    "print('Number of curly brackets: {}'.format(len(lyric_in_curly_brackets)))\n",
    "print('Number of dot: {}'.format(len(dot)))\n",
    "print('Number of star: {}'.format(len(star)))\n",
    "print('Number of semi colon: {}'.format(len(semi_colon)))\n",
    "print('Number of colon: {}'.format(len(colon)))\n",
    "print('Number of exclamation mark: {}'.format(len(exclam_mark)))\n",
    "print('Number of slash: {}'.format(len(slash)))\n",
    "print('Number of slashR: {}'.format(len(slashR)))\n",
    "print('Number of question mark: {}'.format(len(question_mark)))\n",
    "print('Number of hashtag: {}'.format(len(hashtag)))\n",
    "print('Number of percent: {}'.format(len(percent)))\n",
    "print('Number of plus: {}'.format(len(plus)))\n",
    "print('Number of minus: {}'.format(len(minus)))\n",
    "print('Number of comma: {}'.format(len(comma)))\n",
    "print('Number of single quote: {}'.format(len(sg_quote)))\n",
    "print('Number of double quote: {}'.format(len(db_quote)))\n",
    "print('Number of dollar sign: {}'.format(len(dollar_sign)))\n",
    "print('Number of ampersand: {}'.format(len(ampersand)))\n",
    "print('Number of underscore: {}'.format(len(underscore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc0bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of lines\n",
    "song_df['lines'] = song_df['lyric'].map(lambda t: len(re.findall(r'\\n', t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b82afce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove line breaks\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r' \\n|\\n', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d58a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pythainlp\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.corpus.common import thai_stopwords\n",
    "from pythainlp.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "from stop_words import get_stop_words\n",
    "# from pythainlp.ulmfit import process_thai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8db12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\jinnie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "nltk.download('words')\n",
    "th_stop = tuple(thai_stopwords())\n",
    "en_stop = tuple(get_stop_words('en'))\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b409988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word(text):\n",
    "\n",
    "    tokens = word_tokenize(text,engine='newmm')\n",
    "    \n",
    "    # Remove stop words ภาษาไทย และภาษาอังกฤษ\n",
    "    #tokens = [i for i in tokens if not i in th_stop and not i in en_stop]\n",
    "    \n",
    "    # หารากศัพท์ภาษาไทย และภาษาอังกฤษ (Stemming)\n",
    "    # English\n",
    "    tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    # # Thai\n",
    "    # tokens_temp=[]\n",
    "    # for i in tokens:\n",
    "    #     w_syn = wordnet.synsets(i)\n",
    "    #     if (len(w_syn)>0) and (len(w_syn[0].lemma_names('tha'))>0):\n",
    "    #         tokens_temp.append(w_syn[0].lemma_names('tha')[0])\n",
    "    #     else:\n",
    "    #         tokens_temp.append(i)\n",
    "    \n",
    "    # tokens = tokens_temp\n",
    "    \n",
    "    # ลบตัวเลข\n",
    "    tokens = [i for i in tokens if not i.isnumeric()]\n",
    "    \n",
    "    # ลบช่องว่าง\n",
    "    tokens = [i for i in tokens if not ' ' in i]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9854463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9075, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbbe7add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Look at me now ชีวิตกูสบาย Get high อยู่ข้างใน Mansion uh\\rShe wanna drink my kids เธอทำมันเหมือนเธอมี Passion uh\\rทุกจังหวัดที่กูไป Pistol packing never lacking uh\\rพวกแม่งยังคง Cappin and my money they keep adding up uh\\rไม้กางเกงบนตัวกู Chrome heart พวกมึงยังไม่ Cool บอกให้พวกแม่งค่อยๆ Grow up ya\\rกูชอบแดกลีนตอนกู Sober now its over รอเหี้ไรดิ Pour up \\r\\rเขาบอกคนอย่างกูมัวแต่ยุ่งเกี่ยวกับเรื่องยา ยา \\rIm like haha this shit got me trauma \\rก่อนจะได้กิน Steak กูเคยแดกมาม่า\\rกูไม่เชื่อ Karma ตอนนี้แม่กูใส่ Prada\\r\\rกูไม่ค่อยว่างกูอยู่ใน Club21 \\rIm hotter than the summer higher than the sun\\rมึงคิดว่ามันง่ายแต่ไม่ได้ดูกูทำ\\rงานกู one of one และกูทำกันวันต่อวัน\\r\\rกูไม่ร้องขอพระเจ้าให้ Show the way\\rมีแค่กูกับพี่กูที่อยู่ในคลื่นทะเล\\rใครจะ Ride the wave yeah\\rYou gotta make some shake yeah\\r\\rLook at me now ชีวิตกูสบาย Get high อยู่ข้างใน Mansion uh\\rShe wanna drink my kids เธอทำมันเหมือนเธอมี Passion uh\\rทุกจังหวัดที่กูไป Pistol packing never lacking uh\\rพวกแม่งยังคง Cappin and my money they keep adding up uh\\rไม้กางเกงบนตัวกู Chrome heart พวกมึงยังไม่ Cool บอกให้พวกแม่งค่อยๆ Grow up ya\\rกูชอบแดกลีนตอนกู Sober now its over รอเหี้ไรดิ Pour up \\r\\rชีวิตกูสบาย Get high อยู่ข้างใน Mansion uh\\rShe wanna drink my kids เธอทำมันเหมือนเธอมี Passion uh\\rทุกจังหวัดที่กูไป Pistol packing never lacking'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = song_df.loc[0,'lyric']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef17db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>href</th>\n",
       "      <th>lyric</th>\n",
       "      <th>artist</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Of 1</td>\n",
       "      <td>/music/thailyric/23579</td>\n",
       "      <td>Look at me now ชีวิตกูสบาย Get high อยู่ข้างใน...</td>\n",
       "      <td>1mill</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2Turnt</td>\n",
       "      <td>/music/thailyric/23578</td>\n",
       "      <td>Ay can you turn a headphone up\\rIm too turnt r...</td>\n",
       "      <td>1mill</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fu*k It Up</td>\n",
       "      <td>/music/thailyric/23565</td>\n",
       "      <td>I just be takin these drugs takin these drugs\\...</td>\n",
       "      <td>1mill</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On My Own</td>\n",
       "      <td>/music/thailyric/23566</td>\n",
       "      <td>I like counting cash บอกพวกแม่งไม่ต้องโอน\\rมึง...</td>\n",
       "      <td>1mill</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OnSomeShit!</td>\n",
       "      <td>/music/thailyric/23577</td>\n",
       "      <td>I get the racks I get the bag พวกกูชอบ Cash\\rI...</td>\n",
       "      <td>1mill</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>โลกใบเก่า</td>\n",
       "      <td>/music/thailyric/22042</td>\n",
       "      <td>หลายๆ สิ่ง ที่อยู่ข้างใน\\rทบและทวน ยังไม่เคยเข...</td>\n",
       "      <td>zweed_n_roll</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9071</th>\n",
       "      <td>อยากมีความหมาย</td>\n",
       "      <td>/music/thailyric/18114</td>\n",
       "      <td>วันนั้นถ้าเธอบังเอิญ เดินเข้ามา\\rความเหนื่อยล้...</td>\n",
       "      <td>zweed_n_roll</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9072</th>\n",
       "      <td>อยากมีความหมาย (Empty)</td>\n",
       "      <td>/music/thailyric/21524</td>\n",
       "      <td>วันนั้นถ้าเธอบังเอิญ เดินเข้ามา\\rความเหนื่อยล้...</td>\n",
       "      <td>zweed_n_roll</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>อย่าไป (Still)</td>\n",
       "      <td>/music/thailyric/19403</td>\n",
       "      <td>เธอไม่กล้าหรอก เธอนั้นยังรอ\\rเธอนั้นดูก่อน ฉัน...</td>\n",
       "      <td>zweed_n_roll</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9074</th>\n",
       "      <td>อยู่ (You)</td>\n",
       "      <td>/music/thailyric/16666</td>\n",
       "      <td>เพียง ถ้าเธอสบตา ทุกอย่างสวยงาม\\rทำให้ฉันรู้สึ...</td>\n",
       "      <td>zweed_n_roll</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9075 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   song_name                    href  \\\n",
       "0                     1 Of 1  /music/thailyric/23579   \n",
       "1                     2Turnt  /music/thailyric/23578   \n",
       "2                 Fu*k It Up  /music/thailyric/23565   \n",
       "3                  On My Own  /music/thailyric/23566   \n",
       "4                OnSomeShit!  /music/thailyric/23577   \n",
       "...                      ...                     ...   \n",
       "9070               โลกใบเก่า  /music/thailyric/22042   \n",
       "9071          อยากมีความหมาย  /music/thailyric/18114   \n",
       "9072  อยากมีความหมาย (Empty)  /music/thailyric/21524   \n",
       "9073          อย่าไป (Still)  /music/thailyric/19403   \n",
       "9074              อยู่ (You)  /music/thailyric/16666   \n",
       "\n",
       "                                                  lyric        artist  lines  \n",
       "0     Look at me now ชีวิตกูสบาย Get high อยู่ข้างใน...         1mill     31  \n",
       "1     Ay can you turn a headphone up\\rIm too turnt r...         1mill     47  \n",
       "2     I just be takin these drugs takin these drugs\\...         1mill    121  \n",
       "3     I like counting cash บอกพวกแม่งไม่ต้องโอน\\rมึง...         1mill     42  \n",
       "4     I get the racks I get the bag พวกกูชอบ Cash\\rI...         1mill     97  \n",
       "...                                                 ...           ...    ...  \n",
       "9070  หลายๆ สิ่ง ที่อยู่ข้างใน\\rทบและทวน ยังไม่เคยเข...  zweed_n_roll     29  \n",
       "9071  วันนั้นถ้าเธอบังเอิญ เดินเข้ามา\\rความเหนื่อยล้...  zweed_n_roll     35  \n",
       "9072  วันนั้นถ้าเธอบังเอิญ เดินเข้ามา\\rความเหนื่อยล้...  zweed_n_roll     29  \n",
       "9073  เธอไม่กล้าหรอก เธอนั้นยังรอ\\rเธอนั้นดูก่อน ฉัน...  zweed_n_roll     15  \n",
       "9074  เพียง ถ้าเธอสบตา ทุกอย่างสวยงาม\\rทำให้ฉันรู้สึ...  zweed_n_roll     23  \n",
       "\n",
       "[9075 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74ef1246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: thai2fit_wv\n",
      "- Downloading: thai2fit_wv 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62452646/62452646 [00:47<00:00, 1304773.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from typing import List, Tuple\n",
    "import warnings\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from numpy import ndarray, zeros\n",
    "from pythainlp.corpus import get_corpus_path\n",
    "from pythainlp.tokenize import THAI2FIT_TOKENIZER, word_tokenize\n",
    "\n",
    "\n",
    "WV_DIM = 300  # word vector dimension\n",
    "\n",
    "_MODEL_NAME = \"thai2fit_wv\"\n",
    "\n",
    "_TK_SP = \"xxspace\"\n",
    "_TK_EOL = \"xxeol\"\n",
    "\n",
    "def get_model() -> Word2VecKeyedVectors:\n",
    "    path = get_corpus_path(_MODEL_NAME)\n",
    "    return KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "\n",
    "\n",
    "_MODEL = get_model()\n",
    "\n",
    "def sentence_vectorizer(text: str, use_mean: bool = True) -> ndarray:\n",
    "    vec = zeros((1, WV_DIM))\n",
    "\n",
    "    #words = THAI2FIT_TOKENIZER.word_tokenize(text)\n",
    "    words = split_word(text)\n",
    "    print(words)\n",
    "    len_words = len(words)\n",
    "\n",
    "    if not len_words:\n",
    "        return vec\n",
    "\n",
    "    for word in words:\n",
    "        if word == \" \":\n",
    "            word = _TK_SP\n",
    "        elif word == \"\\n\":\n",
    "            word = _TK_EOL\n",
    "\n",
    "        if word in _MODEL.index_to_key:\n",
    "            vec += _MODEL.get_vector(word)\n",
    "\n",
    "    if use_mean:\n",
    "        vec /= len_words\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf1a40a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Look at me now ชีวิตกูสบาย Get high อยู่ข้างใน Mansion uh',\n",
       " 'She wanna drink my kids เธอทำมันเหมือนเธอมี Passion uh',\n",
       " 'ทุกจังหวัดที่กูไป Pistol packing never lacking uh',\n",
       " 'พวกแม่งยังคง Cappin and my money they keep adding up uh',\n",
       " 'ไม้กางเกงบนตัวกู Chrome heart พวกมึงยังไม่ Cool บอกให้พวกแม่งค่อยๆ Grow up ya',\n",
       " 'กูชอบแดกลีนตอนกู Sober now its over รอเหี้ไรดิ Pour up ',\n",
       " 'เขาบอกคนอย่างกูมัวแต่ยุ่งเกี่ยวกับเรื่องยา ยา ',\n",
       " 'Im like haha this shit got me trauma ',\n",
       " 'ก่อนจะได้กิน Steak กูเคยแดกมาม่า',\n",
       " 'กูไม่เชื่อ Karma ตอนนี้แม่กูใส่ Prada',\n",
       " 'กูไม่ค่อยว่างกูอยู่ใน Club21 ',\n",
       " 'Im hotter than the summer higher than the sun',\n",
       " 'มึงคิดว่ามันง่ายแต่ไม่ได้ดูกูทำ',\n",
       " 'งานกู one of one และกูทำกันวันต่อวัน',\n",
       " 'กูไม่ร้องขอพระเจ้าให้ Show the way',\n",
       " 'มีแค่กูกับพี่กูที่อยู่ในคลื่นทะเล',\n",
       " 'ใครจะ Ride the wave yeah',\n",
       " 'You gotta make some shake yeah',\n",
       " 'Look at me now ชีวิตกูสบาย Get high อยู่ข้างใน Mansion uh',\n",
       " 'She wanna drink my kids เธอทำมันเหมือนเธอมี Passion uh',\n",
       " 'ทุกจังหวัดที่กูไป Pistol packing never lacking uh',\n",
       " 'พวกแม่งยังคง Cappin and my money they keep adding up uh',\n",
       " 'ไม้กางเกงบนตัวกู Chrome heart พวกมึงยังไม่ Cool บอกให้พวกแม่งค่อยๆ Grow up ya',\n",
       " 'กูชอบแดกลีนตอนกู Sober now its over รอเหี้ไรดิ Pour up ',\n",
       " 'ชีวิตกูสบาย Get high อยู่ข้างใน Mansion uh',\n",
       " 'She wanna drink my kids เธอทำมันเหมือนเธอมี Passion uh',\n",
       " 'ทุกจังหวัดที่กูไป Pistol packing never lacking']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.replace('\\r\\r', '\\r')\n",
    "text_list = text.split('\\r')\n",
    "text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b2c0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = []\n",
    "\n",
    "for i in range(2):\n",
    "    text = song_df.loc[i,'lyric'].replace('\\r\\r', '\\r')\n",
    "    text_list = text.split('\\r')\n",
    "    text_dict = {'src':[], 'songId':0, 'tgt':''}\n",
    "    for t in text_list:\n",
    "        text_dict['src'].append((split_word(t)))\n",
    "    text_dict['songId'] = i\n",
    "    text_dict['tgt'] = song_df.loc[i,'artist']\n",
    "    json_file.append(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77ad08f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\pattern\\Pattern_BFF\\newmodel\\word2vec.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/pattern/Pattern_BFF/newmodel/word2vec.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m/js_data/\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mthaisum.train.1.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/pattern/Pattern_BFF/newmodel/word2vec.ipynb#ch0000015?line=1'>2</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(json_file, f, ensure_ascii\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "with open('/js_data/','thaisum.train.1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_file, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba5a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dadc8e8bb9ce544ecdba487e4f370facadbb48df51df38eb2f6de5fcc26f1856"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
