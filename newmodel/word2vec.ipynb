{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6631639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\pemza\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\pemza\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\pemza\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\pemza\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\pemza\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148481a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230fc954",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17292/2319813448.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mli\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0msong_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mli\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \"\"\"\n\u001b[1;32m--> 294\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No objects to concatenate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "all_files = glob.glob(\"../../data_lyrics/thaisongs/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    song_df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(song_df)\n",
    "\n",
    "song_df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1ebba0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'song_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17292/3806814661.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# remove !@#$%^&*()_+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlyric_in_round_brackets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\((.*?)\\)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlyric_in_square_brackets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\[(.*?)\\]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlyric_in_curly_brackets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\{(.*?)\\}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'song_df' is not defined"
     ]
    }
   ],
   "source": [
    "# remove !@#$%^&*()_+\n",
    "lyric_in_round_brackets = sum(list(song_df['lyric'].map(lambda s: re.findall(r'\\((.*?)\\)',s))), [])\n",
    "lyric_in_square_brackets = sum(list(song_df['lyric'].map(lambda s: re.findall(r'\\[(.*?)\\]',s))), [])\n",
    "lyric_in_curly_brackets = sum(list(song_df['lyric'].map(lambda s: re.findall(r'\\{(.*?)\\}',s))), [])\n",
    "dot = sum(list(song_df['lyric'].map(lambda s: re.findall('\\.',s))), [])\n",
    "star = sum(list(song_df['lyric'].map(lambda s: re.findall('\\*',s))), [])\n",
    "semi_colon = sum(list(song_df['lyric'].map(lambda s: re.findall('\\;',s))), [])\n",
    "colon = sum(list(song_df['lyric'].map(lambda s: re.findall('\\:',s))), [])\n",
    "exclam_mark = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\!\",s))), [])\n",
    "slash = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\/\",s))), [])\n",
    "slashR = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\\\\",s))), [])\n",
    "question_mark = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\?\",s))), [])\n",
    "hashtag = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\#\",s))), [])\n",
    "percent = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\%\",s))), [])\n",
    "plus = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\+\",s))), [])\n",
    "minus = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\-\",s))), [])\n",
    "comma = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\,\",s))), [])\n",
    "sg_quote = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\'\",s))), [])\n",
    "db_quote = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\\"\",s))), [])\n",
    "dollar_sign = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\$\",s))), [])\n",
    "ampersand = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\&\",s))), [])\n",
    "underscore = sum(list(song_df['lyric'].map(lambda s: re.findall(r\"\\_\",s))), [])\n",
    "\n",
    "\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\((.*?)\\)', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\[(.*?)\\]', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\{(.*?)\\}', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\.', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\*', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\;', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\:', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\!\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\/\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\\\', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\?\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\#\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\%\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\+\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\-\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\,\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r\"\\'\", '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\\"', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\$', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\&', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\_', '', s))\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r'\\(|\\)', '', s))\n",
    "\n",
    "\n",
    "\n",
    "print('Number of round brackets: {}'.format(len(lyric_in_round_brackets)))\n",
    "print('Number of square brackets: {}'.format(len(lyric_in_square_brackets)))\n",
    "print('Number of curly brackets: {}'.format(len(lyric_in_curly_brackets)))\n",
    "print('Number of dot: {}'.format(len(dot)))\n",
    "print('Number of star: {}'.format(len(star)))\n",
    "print('Number of semi colon: {}'.format(len(semi_colon)))\n",
    "print('Number of colon: {}'.format(len(colon)))\n",
    "print('Number of exclamation mark: {}'.format(len(exclam_mark)))\n",
    "print('Number of slash: {}'.format(len(slash)))\n",
    "print('Number of slashR: {}'.format(len(slashR)))\n",
    "print('Number of question mark: {}'.format(len(question_mark)))\n",
    "print('Number of hashtag: {}'.format(len(hashtag)))\n",
    "print('Number of percent: {}'.format(len(percent)))\n",
    "print('Number of plus: {}'.format(len(plus)))\n",
    "print('Number of minus: {}'.format(len(minus)))\n",
    "print('Number of comma: {}'.format(len(comma)))\n",
    "print('Number of single quote: {}'.format(len(sg_quote)))\n",
    "print('Number of double quote: {}'.format(len(db_quote)))\n",
    "print('Number of dollar sign: {}'.format(len(dollar_sign)))\n",
    "print('Number of ampersand: {}'.format(len(ampersand)))\n",
    "print('Number of underscore: {}'.format(len(underscore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc0bc2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'song_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17292/1848182078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# count number of lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msong_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lines'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msong_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lyric'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'song_df' is not defined"
     ]
    }
   ],
   "source": [
    "# count number of lines\n",
    "song_df['lines'] = song_df['lyric'].map(lambda t: len(re.findall(r'\\n', t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82afce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove line breaks\n",
    "song_df['lyric'] = song_df['lyric'].map(lambda s: re.sub(r' \\n|\\n', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pythainlp\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.corpus.common import thai_stopwords\n",
    "from pythainlp.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "from stop_words import get_stop_words\n",
    "# from pythainlp.ulmfit import process_thai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8db12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "nltk.download('words')\n",
    "th_stop = tuple(thai_stopwords())\n",
    "en_stop = tuple(get_stop_words('en'))\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word(text):\n",
    "\n",
    "    tokens = word_tokenize(text,engine='newmm')\n",
    "    \n",
    "    # Remove stop words ภาษาไทย และภาษาอังกฤษ\n",
    "    #tokens = [i for i in tokens if not i in th_stop and not i in en_stop]\n",
    "    \n",
    "    # หารากศัพท์ภาษาไทย และภาษาอังกฤษ (Stemming)\n",
    "    # English\n",
    "    tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    # # Thai\n",
    "    # tokens_temp=[]\n",
    "    # for i in tokens:\n",
    "    #     w_syn = wordnet.synsets(i)\n",
    "    #     if (len(w_syn)>0) and (len(w_syn[0].lemma_names('tha'))>0):\n",
    "    #         tokens_temp.append(w_syn[0].lemma_names('tha')[0])\n",
    "    #     else:\n",
    "    #         tokens_temp.append(i)\n",
    "    \n",
    "    # tokens = tokens_temp\n",
    "    \n",
    "    # ลบตัวเลข\n",
    "    tokens = [i for i in tokens if not i.isnumeric()]\n",
    "    \n",
    "    # ลบช่องว่าง\n",
    "    tokens = [i for i in tokens if not ' ' in i]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9854463",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = song_df.loc[0,'lyric']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef17db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from typing import List, Tuple\n",
    "import warnings\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from numpy import ndarray, zeros\n",
    "from pythainlp.corpus import get_corpus_path\n",
    "from pythainlp.tokenize import THAI2FIT_TOKENIZER, word_tokenize\n",
    "\n",
    "\n",
    "WV_DIM = 300  # word vector dimension\n",
    "\n",
    "_MODEL_NAME = \"thai2fit_wv\"\n",
    "\n",
    "_TK_SP = \"xxspace\"\n",
    "_TK_EOL = \"xxeol\"\n",
    "\n",
    "def get_model() -> Word2VecKeyedVectors:\n",
    "    path = get_corpus_path(_MODEL_NAME)\n",
    "    return KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "\n",
    "\n",
    "_MODEL = get_model()\n",
    "\n",
    "def sentence_vectorizer(text: str, use_mean: bool = True) -> ndarray:\n",
    "    vec = zeros((1, WV_DIM))\n",
    "\n",
    "    #words = THAI2FIT_TOKENIZER.word_tokenize(text)\n",
    "    words = split_word(text)\n",
    "    print(words)\n",
    "    len_words = len(words)\n",
    "\n",
    "    if not len_words:\n",
    "        return vec\n",
    "\n",
    "    for word in words:\n",
    "        if word == \" \":\n",
    "            word = _TK_SP\n",
    "        elif word == \"\\n\":\n",
    "            word = _TK_EOL\n",
    "\n",
    "        if word in _MODEL.index_to_key:\n",
    "            vec += _MODEL.get_vector(word)\n",
    "\n",
    "    if use_mean:\n",
    "        vec /= len_words\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1a40a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text = text.replace('\\r\\r', '\\r')\n",
    "text_list = text.split('\\r')\n",
    "text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = []\n",
    "\n",
    "for i in range(2):\n",
    "    text = song_df.loc[i,'lyric'].replace('\\r\\r', '\\r')\n",
    "    text_list = text.split('\\r')\n",
    "    text_dict = {'src':[], 'songId':0, 'tgt':''}\n",
    "    for t in text_list:\n",
    "        text_dict['src'].append((split_word(t)))\n",
    "    text_dict['songId'] = i\n",
    "    text_dict['tgt'] = song_df.loc[i,'artist']\n",
    "    json_file.append(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('thaisum.train.1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_file, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b1671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74b61129dc21a09fdc11cbb8ab8ed7bd59468d4ab432d84f730f945183c44b80"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
